假设检验
===================


我有一枚硬币，我“声称”它是均匀的，即上抛落地后国徽朝上和朝下的概率是相同的（忽略抛的手法）

然后我抛了5次，结果4次国徽朝上

问，我撒谎了么？


# 一点科学哲学史

如何探寻真理？

三段论 -> 培根的经验主义(归纳和演绎) -> 实证（波普尔）主义

波普尔主义的核心：

- 不能证伪的不是科学

- "真理"是尚未被证伪的命题

**思考1** 根据波普尔主义，数学中的公理和定理是不是科学

# 显著性检验（Fisher Significance Test）


原假设（Null Hypothesis）： p = 0.5

样本数据（Sample）：硬币抛5次，4次朝上

显著性水平(p-value)：在原假设下，观察到样本数据**或者更极端数据**的概率

（1）找到这个样本数据的分布。（独立同步地）抛5次，朝上总数符合二项式分布。

（2）在原假设下，p=0.5

        pvalue = P(X>=4|p=0.5) = P(X=4|p=0.5)+P(X=5|p=0.5) = [C(5,4) + C(5,5)] * 0.5^5 = 0.21875

问题来了，p-value是0.21875，然后咋办？

Fisher会说，再来点数据从而消灭抽样误差

**思考2**假设你听了Fisher的建议，又抛了5次，3次朝上。现在的pvalue是多少？

问题又来了

(1) 显著性水平(alpha)怎么不见了？不是应该拿pvalue去和显著性水平比么？

(2) 怎么没有备择假设？

# 假设检验（Neyman-Pearson Hypothesis Test）

Fisher老爷爷是研究农学的，所以种一季稻谷不行，那就再种一季。重复收集数据的成本不高。

其他学科（特别是社会科学）收集数据的成本是非常高的。假设你只能收集一次数据，怎么办？

Neyman-Pearson假设检验提供了一个比较合理的完整决策逻辑

## 原假设和备择假设

首先，仅仅有原假设是不够的。在实验前，你必须提出一个具体的备择假设。比如，如果硬币不均匀，头朝上的概率是0.3

H0: p=0.5

H1: p=0.7

一个实验结束后，你只有两个选择：拒绝原假设，或者无法拒绝原假设（**作为波普尔主义者，没有证明，只有尚待证伪**）

## 两类错误

在你做出决策后，你会犯两类错误

第一类错误：如果原假设为真，但是你拒绝了它

第二类错误：如果原假设不为真(即H1为真)，但是你没有拒绝它

![two types of error](http://2378nh2nfow32gm3mb25krmuyy.wpengine.netdna-cdn.com/wp-content/uploads/2014/05/Type-I-and-II-errors1-625x468.jpg)

这两类错误的概率分别为显著性水平(alpha)和检验效力(beta)


## 决策方法


第一步：选择一个显著性水平（alpha）和检验效力（beta）

假设alpha = 0.05， beta = 0.2，这是传统的1:4配置。

**思考3** 请描述这两个数的现实含义

第一步：根据alpha和beta计算样本量

假设 N = 1，在H1下，出现x=0的概率是0.3，出现x=1的概率是0.7。如果出现x=0，（根据原假设），pvalue是1，如果出现x=1，pvalue是0.5。根据alpha，均不能拒绝原假设。所以二类错误概率是1，大于0.2。 因此此样本量不符合要求。

**思考4** N=5是否符合要求

用同样的逻辑，可以知道N=10是符合参数配置的最小样本量。（二类错误概率大约为0.15）


第三步：采集数据

第四步：根据样本计算p-value，并且和alpha做进行比较。如果比alpha大，无法拒绝原假设；如果比alpha小，拒绝原假设

假设抛出了6（或以上），拒绝H0；假设抛出了6（或以下），不能拒绝H0

**思考5** 如果H1=0.3，pvalue应该怎么算？

问题来了：为啥我之前学的假设检验没有这么复杂的步骤？

(1) 怎么H1不是H0的补集？！

(2) 为什么我们不教beta？


# 原假设显著性检验（Null Hypothesis Statistical Significance Test）

初等统计学教授的"假设检验"，是Fisher显著性检验和Neyman-Pearson假设检验的结合体。

它从Fisher那里拿来了pvalue，从Neyman-Pearson里拿来了alpha。这个办法由很多问题，但是它易教易用：既有显著性检验的计算便利，又有假设检验的决策便利。

问1：为什么（许多情况下）H1是H0的补集，而不是一个具体的值

答1：在因果检测中，原假设(H0: theta=0)有特殊含义，即改变自变量不改变因变量，即两者没有关系（我们会在回归这一课中详细讲）。它的补集就是有因果关系，强度不论，但是就是有。

问2：为什么我们不教beta？

答2：太难。一般只有在高级数理统计或者实验设计中才学样本设计。此外，大部分社会科学数据集都有样本设计专家操刀设计，数据使用者一般可以不关心beta。但是在业界实验中，不选择beta和样本可能会造成麻烦。


# 大样本下的假设检验

假设我抛了500次硬币，其中256次国徽朝上，244次国徽朝下。

用上述的假设检验步骤，你的pvalue是多少？


        sum(x=256->500) C(500,x)0.5^500 ~= 0.311

根据中央极限定理，500次抛硬币的均值应该趋近于什么分布？你的pvalue是多少？

        N(0.5, sqrt(0.5*0.5/500))

        1-F(500/256) ~= 0.296

第一种做法我们成为exact test，第二种做法就是t-test（在这个数量级上t和normal分布无限接近）。

exact test需要知道原始分布的pdf/pmf函数（很多情况下计算起来非常复杂），而t-test只需要知道样本量，（用Google查）原始分布的均值和标准差，以及（用Excel算）正太分布的取值表就可以。

中央极限定理万岁！


# 用贝叶斯理论来思考假设检验

p-value 用条件概率表示是 P(Data|H0)，但是贝叶斯主义说，脑残，显然应该算 P(H0|Data)。

        P(H0|Data) = P(Data, H0) / P(Data)

要计算P(Data)，就要计算

        P(Data, H) for all H

**思考6**：在之前的设定下，抛5次4次向上，P(p=0.5|n=5,m4)的P(p=0.7|n=5,m=4)分别是多少？

我们一般用Bayes Factor来“做”假设检验，

        BF(H0,H1|Data) = P(H0|Data)/P(H1|Data)

**思考7** 上述设定中的Bayes Factor是什么

进一步的，Bayes Factor可以写作

        BF = P(H0)/P(H1) * P(data|H0)/P(data|H1)

Bayes Factor检验法没有普及开来，由两个重要的因素：

（1）和Fisher显著性检验一样，它缺乏一个具有合理逻辑支撑的决策理论。你得到了Bayes Factor，然后怎么办？

（2）频率学派（Frequentist），比如Fisher本人，认为Bayes Factor里存在先验分布的比值是个Bug。如果不是1:1，怎么设置留下太多主观判断，如果先验分布比是1:1，那就和频率学派的假设检验没有本质，你搞啥花架子


但是，在连续实验（Sequential Test）中，每一次实验都的确带来了新认知，这些认知是可以被继承的。在这个场景下，用贝叶斯方法能比用频率学派方法更容易地解决认知继承的问题。


# 思考题答案

1. 不是，因为公理是无法证伪的（也不需要证伪）。以公理为出发点进行推论的定理因此也无法证伪。所以，不是狭义上的科学并不一定说明它没有价值。

2. X~ Binomial(10, 0.5), P(X>=8) ~= 0.054。Fisher可能会说，这是比较强的证据原假设不成立。

3. 原假设为真时拒绝了原假设的概率是5%。备择假设为真时未能拒绝原假设的概率是20%

4. N=5时，在H0下，只有x=5拒绝原假设。在H1下，不能拒绝原假设的概率为0.832。所以不符合beta要求

5. more extreme = 比观察到的x小！sum(0,x)P(X=x)

6. 必须知道先验分布！令P(p=0.5) = q，P(p=0.7) = (1-q)

        P(p=0.5|data) = 0.5^5*q / (0.5^5*q + 0.7^4*0.3*(1-q))
        P(p=0.7|data) = 0.7^4*0.3*(1-q) / (0.5^5*q + 0.7^4*0.3*(1-q))

7. BF是 

        0.5^5/(0.7^4*0.3) * q/(1-q)

# 课外阅读

[Fisher Test V.S. Neyman-Pearson](https://stats.stackexchange.com/questions/23142/when-to-use-fisher-and-neyman-pearson-framework)

