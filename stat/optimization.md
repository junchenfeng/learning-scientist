最优化问题
================

# 一元二次方程
假设有个一元二次方程

		f(x) = ax^2+bx+c

问什么情况下有最小值？
        
一阶导为0
		
		f'(x) = 2ax + b = 0 
        -> x = -b/(2a)

二阶导大于0        
        
		f''(x) = 2a 
        -> a>0
		
核心：把一个求最值问题变成了一个求解问题。

# 二次型损失函数(Quadratic Loss Function)

假设我们有一组(N个)数据要拟合，目标数据是y，特征数据是X。

假设有个拟合函数是f(x)，我们怎么判断其拟合的好坏呢？

方法1：把函数值和目标数据的差加起来

        sum_{i=1}^N [y_i-f(X_i)]

方法2：把函数值和目标数据的差的平方项加起来

        sum_{i=1}^N [y_i-f(X_i)]^2
        
为什么一般不用方法1呢？因为方法1认为正负误差可以相互抵消，这在大部分情况下是不合理的。

例如，f(x)的拟合误差是{-2,1}；而g(x)的拟合误差是{-10,10}。方法1会认为g(x)更好，而方法2认为f(x)更好。

刚才我们讨论的是二次型**损失函数**。这种损失函数之所以比较受欢迎，因为

- 如果f(x)单调，必然有最小值
- 其几何含义比较好理解

根据第一部分的知识，我们可知最值的条件是

    sum_{i=1}^N 2[y_i-f(X_i)]f'(X_i) = 0

这种方程可能没有显式解(analytics solution)；因此，我们必须求助于数值模拟    
 
# 牛顿法

我们接下来介绍一种最简单的在给定区间求方程解的数值模拟方法：对半法。

假设f(x) 在[a,b]上单调。计算f(a), f(b)。
    
- 如果f(a)f(b)>0，方程在区间上无解。
- f(a) or f(b) = 0，该点是方程的解。
- 如果f(a)f(b)<0，取点c=(a+b)/2。在[a,c], [c,b]上重复对半法

对半法的核心问题在于

（1）步长选择太固定，永远是区间的一半
（2）每次截半后，需要计算两次

牛顿法在对半法的基础上有所改进：

（1）步长与|f'(x)|成反比。一阶导斜率越大，步长越小；一阶导斜率越小，步长越大
（2）方向与sign(f'(x))有关。f'(x)>0，步长为负；f'(x)<0，步长为正。

# 最大似然估计

看到数据后，写出似然函数 P(D|theta) = f(theta)

求最大值。


# 最优化算法的两个问题

## 鞍点

## 局部最优解
特例：参数识别