---
title: "Item Response Theory"
subtitle: "可能是最重要的一课"
author: "冯俊晨"
date: "2018/07/19"
output:
  xaringan::moon_reader:
    css: [default, zh-CN.css]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(dplyr)
library(readr)
library(ggplot2)
```


---
# 跳高的隐喻(1)

记跳高水平是X，杆高为h,是否跳过为Y


---
# 跳高的隐喻(2): 刚性杆

$Y=1$ -> $Pr(X>=h)=1$

*思考* ：没跳过的概率表达是什么？

*bonus思考*：用贝叶斯思维考虑，跳过杆高为Y这个事件怎么影响X的后验概率

跳高水平 = [跳过的最高高度，没跳过的最低高度)

如果可以测无数多次，对于跳高水平的测量可以达到任意精度

---
# 跳高的隐喻(2): 柔性杆

$Y=1$ -> $Pr(X>=h)=p$

我们观察到一系列事件( $h_1$, $Y_1$), ( $h_2$, $Y_2$),...

怎么刻画X呢？事实上我们依然采用夹逼的思想，只不过用似然函数来描述

$$argmax_{X} \prod_{t=1}^T Pr(X>=h_t)^{Y_t}Pr(X<h_t)^{(1-Y_t)}$$

只要为Y选择一个分布，我们就可以用MLE解X

如果我们选择Logit，那么就得到了IRT模型

$$Pr(Y_t=1) = logit(X-h_t)$$


---
# Rasch Model

记学生能力参数为 $\theta$, 题目难度为 $\beta$，答题结果为 $Y$

那么Rasch方程可写为

$$Pr(Y=1) = logit(X-b)$$

问题来了：b怎么衡量？没有b怎么衡量X？

---
# Response Curve

```{r, echo=FALSE}
rasch_data = data.frame(x=seq(-4,4,0.1))
rasch_data = rasch_data %>% mutate(y=1/(1+exp(-x)), model="RASCH")
plot_data = rasch_data
qplot(data=plot_data, x=x, y=y, geom='line', col=model)
```

---
# Response Curve (2)

*思考*： 哪题更难？

```{r, echo=FALSE}
easy_data = data.frame(x=seq(-4,4,0.1))
easy_data = easy_data %>% mutate(y=1/(1+exp(-(x+1))), model="b=1")

hard_data = data.frame(x=seq(-4,4,0.1))
hard_data = hard_data %>% mutate(y=1/(1+exp(-(x-1))), model="b=-1")

plot_data = rbind(rasch_data,easy_data, hard_data)
qplot(data=plot_data, x=x, y=y, geom='line', col=model)
```

---
# 双参数模型

假设 $b=0$

回到杆子的隐喻，如果这个杆子软到“就像一颗海草”，跳不跳的过去纯凭运气，即

$$ Pr(Y=1) = 0.5 \forall x$$
在Rasch模型里，这个很难实现；但是，观察到

$$ 0.5 = logit(0) = logit(0*x+0)$$

因此，我们可以引进一个新的参数来描述题目对于能力的敏感程度

$$Pr(Y=1) = logit(aX-b)$$

我们称 $a$ 为区分度

*思考*: 如果杆是完全刚性的， $a$ 怎么取值?


---
# 双参数模型(RC)

*思考*： 哪题更难

```{r, echo=FALSE}
low_discrimiate_data = data.frame(x=seq(-4,4,0.1))
low_discrimiate_data = low_discrimiate_data %>% mutate(y=1/(1+exp(-0.5*x)), model="alpha=0.5")
high_discrimiate_data = data.frame(x=seq(-4,4,0.1))
high_discrimiate_data = high_discrimiate_data %>% mutate(y=1/(1+exp(-2*x)), model="alpha=2")

plot_data = rbind(rasch_data, low_discrimiate_data, high_discrimiate_data)

qplot(data=plot_data, x=x, y=y, geom='line', col=model)
```


---
# 双参数模型(RC)(2)

*思考*： 哪题更难？

```{r, echo=FALSE}
plot_data = rbind(rasch_data, hard_data, high_discrimiate_data)

qplot(data=plot_data, x=x, y=y, geom='line', col=model)
```

---
# 三参数模型

双参数模型有一条渐近线：$$ Pr(Y=1|X \rightarrow -\inf) \rightarrow 0$$

它说，最差的孩子的正确率是0%

*思考*：双参数模型有几个定点？几条渐近线？他们的现实含义是什么

考虑判断题，渐近线应该在0.5；考虑三选一，渐近线应该在0.33；

事实上，哪怕是填空题，也可能存在渐近线！！

因此，三参数IRT模型增加了猜测系数 $$ Pr(Y=1) = c + (1-c)logit(aX-b)$$

---
# IRT in R（1）

在R中使用IRT
```{r, echo=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
exp_result = read_delim("/Users/fengjunchen/git/learning-scientist/data/exp_result.csv", delim='\t')

Q = data.frame(course_id=as.character(), q1=as.integer(), q2=as.integer())
for (group_name in unique(exp_result$course_id)){
  
  group_data = exp_result %>% filter(course_id==group_name)
  
  valid_users = group_data %>%
    group_by(student_id) %>%
    summarize(n=n()) %>%
    filter(n==2)
  item1 = group_data %>% 
    filter(posttest=='similar', student_id %in% valid_users$student_id) %>%
    dplyr::select(course_id, student_id, master) %>% rename(q1=master)
  item2 = exp_result %>% 
    filter(posttest=='transfer', student_id %in% valid_users$student_id) %>%
    dplyr::select(course_id, student_id, master) %>% rename(q2=master)
  q = merge(item1,item2) %>% dplyr::select (-student_id)
  Q = rbind(Q,q)
}
irt_data = Q %>% dplyr::select(-course_id)
```

```{r, message=FALSE, warning=FALSE}
head(irt_data)
library(ltm)
m1 = rasch(irt_data, constraint = cbind(ncol(irt_data) + 1, 1))  # 1 参数
m2 = rasch(irt_data) # 2 参数
m3 = tpm(irt_data, type = "rasch", max.guessing = 1) # 3 参数
```


---
# IRT in R（2）
```{r, echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow = c(2, 2))
pl1 <- plot(m1)
text(2, 0.35, "Rasch model\nDiscrimination = 1")
pl2 <- plot(m2)
text(2, 0.35, "Rasch model")
pl3 <- plot(m3)
text(2, 0.35, "Rasch model\nwith Guessing parameter")
```

---
# IRT in R（3）
```{r, echo=FALSE, message=FALSE, warning=FALSE}
irt_param = data.frame(course_id=as.character(), item_id=as.character(), model=as.character(),alpha=as.numeric(), beta=as.numeric())
for (group_name in unique(exp_result$course_id)){
  group_data = Q %>%filter(course_id==group_name) %>% dplyr::select(-course_id)
  m1 = rasch(group_data, constraint = cbind(ncol(group_data) + 1, 1))
  m2 = rasch(group_data)
  irt_param = rbind(irt_param, data.frame(course_id=group_name, item_id='q1', model='RASCH', alpha=1, beta=m1$coefficients[1,1]))
  irt_param = rbind(irt_param, data.frame(course_id=group_name, item_id='q2', model='RASCH', alpha=1, beta=m1$coefficients[2,1]))
  irt_param = rbind(irt_param, data.frame(course_id=group_name, item_id='q1', model='2PL', alpha=m2$coefficients[1,2], beta=m2$coefficients[1,1]))
  irt_param = rbind(irt_param, data.frame(course_id=group_name, item_id='q2', model='2PL', alpha=m2$coefficients[2,2], beta=m2$coefficients[2,1]))
    }
```
```{r, echo=FALSE}
print(irt_param)
```
---
# 多维IRT

跳高的隐喻有一个重要的假设，那就是我们只衡量一维能力值

然而实际上我们可能需要衡量多维能力值

这就打开了一个潘多拉魔盒

---
# 噩梦（1）：方程形式

多维IRT有两种做法

$$ Pr(Y=1) = logit(a_1X_1+a_2X_2-b)$$

$$ Pr(Y=1) = logit(a_1X_1-b_1)logit(a_2X_2-b_2)$$

*思考*： 这两种方法的现实含义是什么
*思考*：可以又加又乘么？

---
# 噩梦（2）：变量可解释性


考虑一元IRT模型，我们真的在测量数学能力么？

答案是否定的。我们在做一个考试间的**可比排序**；仅此而已。

如果不考虑变量的可解释性，（在合理的模型选择和估计下），多元IRT可以增加排序的稳定性和正确性。$X$数量和形式的选择可以通过预测误差来调整。

如果要考虑变量的可解释性（比如锚定$X_k$到知识点），多元IRT方程就变成一个非常复杂的建模问题，并且可能破坏了IRT方程自身良好的预测能力！！

---
# 降维？

问：如果一道题挂了多个知识点，是否可以拆为多条数据；然后每个知识点用一维IRT模型来估计？

答：不能。因为这样无法合理归咎。

对了就全会

错了就全不会


---
# IRT模型的局限

我们现在讨论IRT模型最主要的局限。

在跳高比赛中，一个极端重要的假设是，运动员的水平是一个定值（或者严谨的说，不会随着每一次跳跃而改变）。

类似的，我们认为，在考试中，孩子也不会随着做题而进步/退步。

换句话说，不存在 **学习** 的可能性

---
# 应用

（1）IRT非常适合用于以排位为主要目标的终结性测评，它解决了异质试卷结果的比较问题。从ETS长期实践来看，效果也非常不错

（2）IRT模型并不适合用于形成行测评。第一，它根本上否认学习的可能性；第二，它无法与知识点结构共存

（3）以IRT为基础，可以构建[自适应测评](http://www.fengjunchen.com/cat/)；但是因为它并不是适合做自适应学习引擎（这个教训至少值1000w人民币）；甚至不能用它来做练习题的筛选



